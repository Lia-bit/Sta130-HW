{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b4c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X          Y Unique Squirrel ID Hectare Shift      Date  \\\n",
      "0 -73.956134  40.794082     37F-PM-1014-03     37F    PM  10142018   \n",
      "1 -73.968857  40.783783     21B-AM-1019-04     21B    AM  10192018   \n",
      "2 -73.974281  40.775534     11B-PM-1014-08     11B    PM  10142018   \n",
      "3 -73.959641  40.790313     32E-PM-1017-14     32E    PM  10172018   \n",
      "4 -73.970268  40.776213     13E-AM-1017-05     13E    AM  10172018   \n",
      "\n",
      "   Hectare Squirrel Number    Age Primary Fur Color Highlight Fur Color  ...  \\\n",
      "0                        3    NaN               NaN                 NaN  ...   \n",
      "1                        4    NaN               NaN                 NaN  ...   \n",
      "2                        8    NaN              Gray                 NaN  ...   \n",
      "3                       14  Adult              Gray                 NaN  ...   \n",
      "4                        5  Adult              Gray            Cinnamon  ...   \n",
      "\n",
      "    Kuks  Quaas  Moans Tail flags Tail twitches  Approaches  Indifferent  \\\n",
      "0  False  False  False      False         False       False        False   \n",
      "1  False  False  False      False         False       False        False   \n",
      "2  False  False  False      False         False       False        False   \n",
      "3  False  False  False      False         False       False        False   \n",
      "4  False  False  False      False         False       False        False   \n",
      "\n",
      "   Runs from  Other Interactions                                    Lat/Long  \n",
      "0      False                 NaN  POINT (-73.9561344937861 40.7940823884086)  \n",
      "1      False                 NaN  POINT (-73.9688574691102 40.7837825208444)  \n",
      "2      False                 NaN  POINT (-73.97428114848522 40.775533619083)  \n",
      "3       True                 NaN  POINT (-73.9596413903948 40.7903128889029)  \n",
      "4      False                 NaN  POINT (-73.9702676472613 40.7762126854894)  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the New York City Squirrel Census 2018 dataset from the provided URL\n",
    "url = \"https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\"\n",
    "df_squirrels = pd.read_csv(url)\n",
    "df_squirrels.head()\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(df_squirrels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c21753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X                                                0\n",
      "Y                                                0\n",
      "Unique Squirrel ID                               0\n",
      "Hectare                                          0\n",
      "Shift                                            0\n",
      "Date                                             0\n",
      "Hectare Squirrel Number                          0\n",
      "Age                                            121\n",
      "Primary Fur Color                               55\n",
      "Highlight Fur Color                           1086\n",
      "Combination of Primary and Highlight Color       0\n",
      "Color notes                                   2841\n",
      "Location                                        64\n",
      "Above Ground Sighter Measurement               114\n",
      "Specific Location                             2547\n",
      "Running                                          0\n",
      "Chasing                                          0\n",
      "Climbing                                         0\n",
      "Eating                                           0\n",
      "Foraging                                         0\n",
      "Other Activities                              2586\n",
      "Kuks                                             0\n",
      "Quaas                                            0\n",
      "Moans                                            0\n",
      "Tail flags                                       0\n",
      "Tail twitches                                    0\n",
      "Approaches                                       0\n",
      "Indifferent                                      0\n",
      "Runs from                                        0\n",
      "Other Interactions                            2783\n",
      "Lat/Long                                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find missing data counts for each column\n",
    "missing_data_counts = df_squirrels.isnull().sum()\n",
    "\n",
    "# Display missing data counts\n",
    "print(missing_data_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca292f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 3023 rows and 31 columns.\n"
     ]
    }
   ],
   "source": [
    "# Question 2.1\n",
    "\n",
    "# Display the shape of the dataset\n",
    "rows, columns = df_squirrels.shape\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43bfc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2.2\n",
    "\n",
    "# Observation(rows): Each row represents one sighting of a squirrel, including details such as date, age, behavior, fur colors, and specific location.\n",
    "# Variable(columns): Each colums represents a specific variable in a dataset that is being measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1741dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of numeric columns:\n",
      "                 X            Y          Date  Hectare Squirrel Number\n",
      "count  3023.000000  3023.000000  3.023000e+03              3023.000000\n",
      "mean    -73.967184    40.780853  1.011949e+07                 4.123718\n",
      "std       0.007726     0.010285  4.246671e+04                 3.096492\n",
      "min     -73.981159    40.764911  1.006202e+07                 1.000000\n",
      "25%     -73.973102    40.771676  1.008202e+07                 2.000000\n",
      "50%     -73.968594    40.778166  1.012202e+07                 3.000000\n",
      "75%     -73.960189    40.791219  1.014202e+07                 6.000000\n",
      "max     -73.949722    40.800119  1.020202e+07                23.000000\n",
      "\n",
      "Summary of all columns:\n",
      "                  X            Y Unique Squirrel ID Hectare Shift  \\\n",
      "count   3023.000000  3023.000000               3023    3023  3023   \n",
      "unique          NaN          NaN               3018     339     2   \n",
      "top             NaN          NaN      7D-PM-1010-01     14D    PM   \n",
      "freq            NaN          NaN                  2      32  1676   \n",
      "mean     -73.967184    40.780853                NaN     NaN   NaN   \n",
      "std        0.007726     0.010285                NaN     NaN   NaN   \n",
      "min      -73.981159    40.764911                NaN     NaN   NaN   \n",
      "25%      -73.973102    40.771676                NaN     NaN   NaN   \n",
      "50%      -73.968594    40.778166                NaN     NaN   NaN   \n",
      "75%      -73.960189    40.791219                NaN     NaN   NaN   \n",
      "max      -73.949722    40.800119                NaN     NaN   NaN   \n",
      "\n",
      "                Date  Hectare Squirrel Number    Age Primary Fur Color  \\\n",
      "count   3.023000e+03              3023.000000   2902              2968   \n",
      "unique           NaN                      NaN      3                 3   \n",
      "top              NaN                      NaN  Adult              Gray   \n",
      "freq             NaN                      NaN   2568              2473   \n",
      "mean    1.011949e+07                 4.123718    NaN               NaN   \n",
      "std     4.246671e+04                 3.096492    NaN               NaN   \n",
      "min     1.006202e+07                 1.000000    NaN               NaN   \n",
      "25%     1.008202e+07                 2.000000    NaN               NaN   \n",
      "50%     1.012202e+07                 3.000000    NaN               NaN   \n",
      "75%     1.014202e+07                 6.000000    NaN               NaN   \n",
      "max     1.020202e+07                23.000000    NaN               NaN   \n",
      "\n",
      "       Highlight Fur Color  ...   Kuks  Quaas  Moans Tail flags Tail twitches  \\\n",
      "count                 1937  ...   3023   3023   3023       3023          3023   \n",
      "unique                  10  ...      2      2      2          2             2   \n",
      "top               Cinnamon  ...  False  False  False      False         False   \n",
      "freq                   767  ...   2921   2973   3020       2868          2589   \n",
      "mean                   NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "std                    NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "min                    NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "25%                    NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "50%                    NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "75%                    NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "max                    NaN  ...    NaN    NaN    NaN        NaN           NaN   \n",
      "\n",
      "       Approaches Indifferent Runs from Other Interactions  \\\n",
      "count        3023        3023      3023                240   \n",
      "unique          2           2         2                197   \n",
      "top         False       False     False    runs from (dog)   \n",
      "freq         2845        1569      2345                  9   \n",
      "mean          NaN         NaN       NaN                NaN   \n",
      "std           NaN         NaN       NaN                NaN   \n",
      "min           NaN         NaN       NaN                NaN   \n",
      "25%           NaN         NaN       NaN                NaN   \n",
      "50%           NaN         NaN       NaN                NaN   \n",
      "75%           NaN         NaN       NaN                NaN   \n",
      "max           NaN         NaN       NaN                NaN   \n",
      "\n",
      "                                          Lat/Long  \n",
      "count                                         3023  \n",
      "unique                                        3023  \n",
      "top     POINT (-73.9561344937861 40.7940823884086)  \n",
      "freq                                             1  \n",
      "mean                                           NaN  \n",
      "std                                            NaN  \n",
      "min                                            NaN  \n",
      "25%                                            NaN  \n",
      "50%                                            NaN  \n",
      "75%                                            NaN  \n",
      "max                                            NaN  \n",
      "\n",
      "[11 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Simple summaries of the columns in the dataset\n",
    "# Generate descriptive statistics for numeric columns\n",
    "summary_numeric = df_squirrels.describe()\n",
    "print(\"Summary of numeric columns:\")\n",
    "print(summary_numeric)\n",
    "\n",
    "# Generate descriptive statistics for all columns, including non-numeric\n",
    "summary_all = df_squirrels.describe(include='all')\n",
    "print(\"\\nSummary of all columns:\")\n",
    "print(summary_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05baf092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'Primary Fur Color':\n",
      "Primary Fur Color\n",
      "Gray        2473\n",
      "Cinnamon     392\n",
      "Black        103\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For example, find the count of unique values within a column 'Primary Fur Color'\n",
    "value_counts_column = df_squirrels['Primary Fur Color'].value_counts()\n",
    "print(\"\\nValue counts for 'Primary Fur Color':\")\n",
    "print(value_counts_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b0a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "\n",
    "# The df.shape() and df.describe() functions are used for different data analyses. \n",
    "# df.shape produces a tuple containing the total number of rows and columns in a dataset, including all columns regardless of data type, giving a rapid overview of its size. \n",
    "# df.describe() returns specific descriptive statistics,and only analyzes numeric columns by default.\n",
    "# The \"count\" in df.describe() represents the number of non-null (non-missing) entries for each numeric column. If a column has missing values, its \"count\" will be less than the total number of rows indicated by df.shape()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5790c3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns:\n",
      "Index(['Unique Squirrel ID', 'Hectare', 'Shift', 'Age', 'Primary Fur Color',\n",
      "       'Highlight Fur Color', 'Combination of Primary and Highlight Color',\n",
      "       'Color notes', 'Location', 'Above Ground Sighter Measurement',\n",
      "       'Specific Location', 'Running', 'Chasing', 'Climbing', 'Eating',\n",
      "       'Foraging', 'Other Activities', 'Kuks', 'Quaas', 'Moans', 'Tail flags',\n",
      "       'Tail twitches', 'Approaches', 'Indifferent', 'Runs from',\n",
      "       'Other Interactions', 'Lat/Long'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Question 4(a)\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_columns = df_squirrels.select_dtypes(exclude=['number']).columns\n",
    "print(\"Non-numeric columns:\")\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6474f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "X                                                0\n",
      "Y                                                0\n",
      "Unique Squirrel ID                               0\n",
      "Hectare                                          0\n",
      "Shift                                            0\n",
      "Date                                             0\n",
      "Hectare Squirrel Number                          0\n",
      "Age                                            121\n",
      "Primary Fur Color                               55\n",
      "Highlight Fur Color                           1086\n",
      "Combination of Primary and Highlight Color       0\n",
      "Color notes                                   2841\n",
      "Location                                        64\n",
      "Above Ground Sighter Measurement               114\n",
      "Specific Location                             2547\n",
      "Running                                          0\n",
      "Chasing                                          0\n",
      "Climbing                                         0\n",
      "Eating                                           0\n",
      "Foraging                                         0\n",
      "Other Activities                              2586\n",
      "Kuks                                             0\n",
      "Quaas                                            0\n",
      "Moans                                            0\n",
      "Tail flags                                       0\n",
      "Tail twitches                                    0\n",
      "Approaches                                       0\n",
      "Indifferent                                      0\n",
      "Runs from                                        0\n",
      "Other Interactions                            2783\n",
      "Lat/Long                                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question 4(b)\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df_squirrels.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c1a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "\n",
    "# Difference between an ‘attribute' and a 'method'\n",
    "# An attribute is a property of a data structure that provides information about it without requiring any operations, such as its shape or column names. It doesn't need parenthesis because it's not a function. \n",
    "# A method is a data structure-related function that performs specialized actions such as calculating statistics or filtering data. Methods require parenthesis because they may accept parameters and run code to manipulate or analyze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5ddb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "\n",
    "# The count indicates how many valid data points are in each column.\n",
    "# The mean calculates the average value of the column\n",
    "# The standard deviation(std) measures how widely distributed the values are around the mean.\n",
    "# The minimum (min) represent the smallest found in the column.\n",
    "# The maximum (max) represent the smallest and biggest values found in the column.\n",
    "# The 25% (first quartile) is the figure below which 25% of the data falls, indicating a smaller percentage of the data.\n",
    "# The 50% (median) provides a measure of the central tendency that is not influenced by extreme values.\n",
    "# The 75% (third quartile) is the amount below which 75% of the data falls, representing the data's top spread.\n",
    "# Summary statistics such as mean, standard deviation, and quartiles can only be calculated for numerical variables because they necessitate mathematical operations.\n",
    "# df.describe() handles missing data by eliminating missing values and calculating statistics purely on the non-missing values, as specified by the \"count\" for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14c134f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe after dropping rows with missing values:\n",
      "(1, 31)\n"
     ]
    }
   ],
   "source": [
    "# Question 7.1  An example of a \"use case\"\n",
    "\n",
    "# Scenario: You have a dataset where only a small percentage of the data points are missing. The missing values are scattered across multiple columns, and removing rows with missing data will not significantly reduce the dataset's size.\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df_squirrels.dropna()\n",
    "print(\"Dataframe after dropping rows with missing values:\")\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f5f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe after deleting a column with many missing values or irrelevant data:\n",
      "(3023, 29)\n"
     ]
    }
   ],
   "source": [
    "# Question 7.2  An example of \"the opposite use case\"\n",
    "\n",
    "# Scenario:You have a dataset with a column that is largely irrelevant to your analysis or has too many missing values, making it unfit for use.\n",
    "# Delete a column with too many missing values or irrelevant data\n",
    "del df_squirrels['Other Interactions']  \n",
    "\n",
    "print(\"Dataframe after deleting a column with many missing values or irrelevant data:\")\n",
    "print(df_squirrels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adb86758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7.3\n",
    "\n",
    "# Applying del df['col'] before df.dropna() removes columns with many missing values first, preserving more rows and improving data quality.\n",
    "# This approach also focuses the analysis on relevant information and reduces computational overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05763ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to delete (more than 50% missing values):\n",
      "Index(['Color notes', 'Specific Location', 'Other Activities'], dtype='object')\n",
      "Before cleaning:\n",
      "Number of rows: 3023, Number of columns: 29\n",
      "\n",
      "After cleaning:\n",
      "Number of rows: 1822, Number of columns: 26\n"
     ]
    }
   ],
   "source": [
    "# Question 7.4\n",
    "\n",
    "# Step 1: Check for missing values in each column\n",
    "missing_values = df_squirrels.isnull().sum()\n",
    "total_rows = df_squirrels.shape[0]\n",
    "\n",
    "# Identify columns with more than 50% missing values\n",
    "columns_to_delete = missing_values[missing_values > (0.5 * total_rows)].index\n",
    "print(\"Columns to delete (more than 50% missing values):\")\n",
    "print(columns_to_delete)\n",
    "\n",
    "# Step 2: Delete columns with too many missing values\n",
    "df_squirrels.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "# Step 3: Drop rows with any remaining missing values\n",
    "df_cleaned = df_squirrels.dropna()\n",
    "\n",
    "# Before and after report\n",
    "print(\"Before cleaning:\")\n",
    "print(f\"Number of rows: {total_rows}, Number of columns: {df_squirrels.shape[1] + len(columns_to_delete)}\")\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"Number of rows: {df_cleaned.shape[0]}, Number of columns: {df_cleaned.shape[1]}\")\n",
    "# Question 7.4 Justification\n",
    "# Columns with more than 50% missing values should be deleted first to retain as much useful data as possible.\n",
    "# Afterward, dropping rows with remaining missing values ensures a complete dataset, simplifying analysis and reducing the risk of errors in modeling or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a22dca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7.4 Before and After\" Report\n",
    "\n",
    "# Before Cleaning:\n",
    "# Number of rows: (e.g., 1000)\n",
    "# Number of columns: (e.g., 20)\n",
    "# Columns with missing values: [Column_A (80%), Column_B (60%), …]\n",
    "\n",
    "# After Cleaning:\n",
    "# Number of rows: (e.g., 850)\n",
    "# Number of columns: (e.g., 18)\n",
    "# All missing values removed; dataset is clean and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd1ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "class                                                            \n",
      "First   186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "Second  173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "Third   355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "# Question 8.1\n",
    "#The method df.groupby(\"col1\")[\"col2\"].describe() is used in pandas to group the data frame df by unique values in the column \"col1\", and then calculate summary statistics for the column \"col2\" within each group.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and describe 'age'\n",
    "grouped_data = titanic_df.groupby(\"class\")[\"age\"].describe()\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2f03756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8.2\n",
    "# df.describe() provides a summary of data completeness and basic statistics for each column, while df.groupby(\"col1\")[\"col2\"].describe() offers a detailed analysis of the characteristics and sizes of different groups based on a specific column. \n",
    "# The group-specific method focuses on understanding the properties of each group, where the counts are essential for assessing the reliability of statistical comparisons between those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1906cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8.3\n",
    "# ChatBot versus google performance\n",
    "# A ChatBot is great for simple coding problems, providing quick, personalized feedback for quick resolution. \n",
    "# Google is more suited for challenging or uncommon circumstances, as well as exploring multiple contexts and approaches, as it provides a diverse range of information and perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfd3e6a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1815248895.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[54], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    NameError: name 'pd' is not defined\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Error A: Forget to Include import pandas as pd\n",
    "\n",
    "# Code with Error\n",
    "# Trying to use pandas without importing it\n",
    "df_squirrels = pd.read_csv(url)\n",
    "\n",
    "# Error Message\n",
    "NameError: name 'pd' is not defined\n",
    "\n",
    "# Resolution with ChatBot: A ChatBot would quickly identify that this is a common error where the pandas library has not been imported. It would suggest adding import pandas as pd at the beginning of your script.\n",
    "# Resolution with Google: A search for \"NameError: name 'pd' is not defined\" would yield similar advice: that you need to import the pandas library. Multiple resources (e.g., Stack Overflow, tutorials) would provide the same solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62b7a15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Error B: Mistype the File URL\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Code with Error\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Incorrect URL\u001b[39;00m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://data.cityofnewyork.us/api/views/vfnx-vebw/rows1.csv?accessType=DOWNLOAD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df_squirrels \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Error Message\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# HTTPError: 404 Client Error: Not Found for url: 'https://data.cityofnewyork.us/api/views/vfnx-vebw/rows1.csv?accessType=DOWNLOAD'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Resolution: Correct the URL by ensuring it matches the correct file path\u001b[39;00m\n\u001b[1;32m     12\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Error B:  Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "\n",
    "# Code with Error\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Error Message\n",
    "FileNotFoundError: [Errno 2] No such file or directory: 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv'\n",
    "\n",
    "# Resolution with ChatBot: The ChatBot would recognize this error and suggest checking the file name or URL for typos. It would point out that the file 'titanics.csv' doesn't exist and suggest correcting it to 'titanic.csv'.\n",
    "# Resolution with Google: A search for FileNotFoundError: [Errno 2] No such file or directory would lead to articles and discussions about checking the file path or URL for mistakes. The advice would be the same, but it might take longer to connect the dots manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14929054",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Squirrels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Error B: Use a DataFrame Before Assignment\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Code with Error\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Using incorrect DataFrame name (e.g., 'df_Squirrels' instead of 'df_squirrels')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdf_Squirrels\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhectare\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Error Message\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# NameError: name 'df_Squirrels' is not defined\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Resolution: Ensure the correct case-sensitive variable name is used\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df_squirrels\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhectare\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_Squirrels' is not defined"
     ]
    }
   ],
   "source": [
    "# Error C: Use a DataFrame Before Assignment\n",
    "\n",
    "# Code with Error\n",
    "# Incorrectly referencing a DataFrame variable that has not been assigned\n",
    "DF_squirrels.groupby(\"Primary Fur Color\")[\"Age\"].describe()\n",
    "\n",
    "# Error Message\n",
    "NameError: name 'DF_squirrels' is not defined\n",
    "\n",
    "# Resolution with ChatBot: The ChatBot would identify the case sensitivity issue in Python and suggest using the correct variable name (df_squirrels).\n",
    "# Resolution with Google: A search for NameError: name 'DF_squirrels' is not defined would provide general advice about Python variable names, but might not be as context-specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30f7a8f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2501652797.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_squirrels = pd.read_csv(url\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Error D: Missing Parenthesis\n",
    "\n",
    "# Code with Error\n",
    "# Missing closing parenthesis\n",
    "df_squirrels = pd.read_csv(url\n",
    "\n",
    "# Error Message\n",
    "SyntaxError: unexpected EOF while parsing\n",
    "\n",
    "# Resolution with ChatBot: The ChatBot would suggest checking for missing parentheses, quotes, or brackets, and highlight that the syntax error is due to a missing closing parenthesis.\n",
    "# Resolution with Google: A search for SyntaxError: unexpected EOF while parsing would provide similar information, but might require reading through more general examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64fbfcbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (196820665.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[49], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    AttributeError: 'DataFrame' object has no attribute 'group_by'\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Error E: Mistyped Function Names\n",
    "\n",
    "# Code with Error\n",
    "df_squirrels.group_by(\"hectare\")[\"age\"].describe()\n",
    "\n",
    "# Error Message\n",
    "AttributeError: 'DataFrame' object has no attribute 'group_by'\n",
    "\n",
    "# Resolution with ChatBot: The ChatBot would recognize the typo in the function name and suggest using the correct function (groupby instead of group_by).\n",
    "# Resolution with Google: A search for AttributeError: 'DataFrame' object has no attribute 'group_by' would yield similar results, explaining the correct function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb99d654",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Error F: Use an Incorrect Column Name\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Code with Error\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Using a column name that doesn't exist\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdf_squirrels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHectare\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Error Message\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;167;01mKeyError\u001b[39;00m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHectare\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: age'"
     ]
    }
   ],
   "source": [
    "# Error F: Use an Incorrect Column Name\n",
    "\n",
    "# Code with Error\n",
    "# Using a column name that doesn't exist\n",
    "df_squirrels.groupby(\"Primary Fur Colour\")[\"Age\"].describe()\n",
    "\n",
    "# Error Message\n",
    "KeyError: 'Primary Fur Colour'\n",
    "\n",
    "# Resolution with ChatBot: The ChatBot would suggest checking the column names in your DataFrame and point out the typo in \"Colour\" (correct should be \"Color\").\n",
    "# Resolution with Google: A search for KeyError: 'Primary Fur Colour' would give general advice about KeyErrors, but you might need to cross-check the column names manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2974809",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2040201394.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[51], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    NameError: name 'hectare' is not defined\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Error G: Forget to Use Quotes for Column Names\n",
    "\n",
    "# Code with Error\n",
    "df_squirrels.groupby(Primary Fur Color)[\"Age\"].describe()\n",
    "\n",
    "# Error Message\n",
    "SyntaxError: invalid syntax\n",
    "\n",
    "# esolution with ChatBot: The ChatBot would suggest that column names should be enclosed in quotes since they are strings, not variables.\n",
    "# Resolution with Google: A search for SyntaxError: invalid syntax might offer a range of examples, some relevant and some not. You would need to figure out the specific context of your error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78741375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9\n",
    "# Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360d8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot Summary Link: (3 Sessions)\n",
    "\n",
    "#1 Question 1: https://chatgpt.com/share/dcadc0ac-084b-4d37-89fa-62d37243dde1\n",
    "#2 Question 2-7: https://chatgpt.com/share/f5b1a22c-e912-4afa-85db-54311862b4e2\n",
    "#3 Question 8-9: https://chatgpt.com/share/82db9730-b1bd-4446-bbdf-052ac2fead2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9c3977",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1273572226.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    1. **Import Libraries**: Import the `pandas` library, which is essential for data manipulation.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Summaries of ChatBot Session: Question 1\n",
    "\n",
    "# Here is the final working version of the code to complete Step 1, which loads the \"NYC Squirrel Census 2018\" dataset, checks for missing values, and displays the count of missing values for each column:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the NYC Squirrel Census 2018 dataset\n",
    "url = \"https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\"\n",
    "df_squirrels = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(df_squirrels.head())\n",
    "\n",
    "# Find missing data counts for each column\n",
    "missing_data_counts = df_squirrels.isnull().sum()\n",
    "\n",
    "# Display missing data counts\n",
    "print(\"Missing Data Counts for Each Column:\")\n",
    "print(missing_data_counts)\n",
    "``\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Import Libraries**: Import the `pandas` library, which is essential for data manipulation.\n",
    "2. **Load the Dataset**: Use the `pd.read_csv()` function to load the dataset from the provided URL.\n",
    "3. **Preview Data**: Use `df_squirrels.head()` to display the first few rows, ensuring the dataset loads correctly.\n",
    "4. **Check for Missing Values**: The `isnull().sum()` function identifies and counts missing values in each column.\n",
    "5. **Output Missing Data Counts**: Print out the counts of missing values for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09630195",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1273572226.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    1. **Import Libraries**: Import the `pandas` library, which is essential for data manipulation.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Summaries of ChatBot Session: Question 1\n",
    "\n",
    "# Here is the final working version of the code to complete Step 1, which loads the \"NYC Squirrel Census 2018\" dataset, checks for missing values, and displays the count of missing values for each column:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the NYC Squirrel Census 2018 dataset\n",
    "url = \"https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\"\n",
    "df_squirrels = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(df_squirrels.head())\n",
    "\n",
    "# Find missing data counts for each column\n",
    "missing_data_counts = df_squirrels.isnull().sum()\n",
    "\n",
    "# Display missing data counts\n",
    "print(\"Missing Data Counts for Each Column:\")\n",
    "print(missing_data_counts)\n",
    "``\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Import Libraries**: Import the `pandas` library, which is essential for data manipulation.\n",
    "2. **Load the Dataset**: Use the `pd.read_csv()` function to load the dataset from the provided URL.\n",
    "3. **Preview Data**: Use `df_squirrels.head()` to display the first few rows, ensuring the dataset loads correctly.\n",
    "4. **Check for Missing Values**: The `isnull().sum()` function identifies and counts missing values in each column.\n",
    "5. **Output Missing Data Counts**: Print out the counts of missing values for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd578d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1273572226.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    1. **Import Libraries**: Import the `pandas` library, which is essential for data manipulation.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Summaries of ChatBot Session: Question 1\n",
    "\n",
    "# Here is the final working version of the code to complete Step 1, which loads the \"NYC Squirrel Census 2018\" dataset, checks for missing values, and displays the count of missing values for each column:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the NYC Squirrel Census 2018 dataset\n",
    "url = \"https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\"\n",
    "df_squirrels = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(df_squirrels.head())\n",
    "\n",
    "# Find missing data counts for each column\n",
    "missing_data_counts = df_squirrels.isnull().sum()\n",
    "\n",
    "# Display missing data counts\n",
    "print(\"Missing Data Counts for Each Column:\")\n",
    "print(missing_data_counts)\n",
    "``\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **Import Libraries**: Import the `pandas` library, which is essential for data manipulation.\n",
    "2. **Load the Dataset**: Use the `pd.read_csv()` function to load the dataset from the provided URL.\n",
    "3. **Preview Data**: Use `df_squirrels.head()` to display the first few rows, ensuring the dataset loads correctly.\n",
    "4. **Check for Missing Values**: The `isnull().sum()` function identifies and counts missing values in each column.\n",
    "5. **Output Missing Data Counts**: Print out the counts of missing values for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0752c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1195498372.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    ```python\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Summaries of ChatBot Session: Question 2-7\n",
    "\n",
    "# Here is the final working version of the code that we created together, which includes all the steps to handle missing data by identifying columns with excessive missing values, deleting them, and then dropping any remaining rows with missing values.\n",
    "\n",
    "### Final Working Code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace with your local dataset path or URL)\n",
    "url = \"https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\"\n",
    "df_squirrels = pd.read_csv(url)\n",
    "\n",
    "# Step 1: Check for missing values in each column\n",
    "missing_values = df_squirrels.isnull().sum()\n",
    "total_rows = df_squirrels.shape[0]\n",
    "\n",
    "print(\"Missing values in each column before cleaning:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Step 2: Identify columns with more than 50% missing values\n",
    "columns_to_delete = missing_values[missing_values > (0.5 * total_rows)].index\n",
    "print(\"\\nColumns to delete (more than 50% missing values):\")\n",
    "print(columns_to_delete)\n",
    "\n",
    "# Step 3: Delete columns with too many missing values\n",
    "df_squirrels.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "# Step 4: Drop rows with any remaining missing values\n",
    "df_cleaned = df_squirrels.dropna()\n",
    "\n",
    "# Before and after report\n",
    "print(\"\\nBefore cleaning:\")\n",
    "print(f\"Number of rows: {total_rows}, Number of columns: {df_squirrels.shape[1] + len(columns_to_delete)}\")\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"Number of rows: {df_cleaned.shape[0]}, Number of columns: {df_cleaned.shape[1]}\")\n",
    "\n",
    "# Optional: Display the cleaned DataFrame (first few rows)\n",
    "print(\"\\nCleaned DataFrame (first 5 rows):\")\n",
    "print(df_cleaned.head())\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Load the Dataset:**\n",
    "   - The dataset is loaded using `pd.read_csv()` from the provided URL. You can replace the URL with your local file path if needed.\n",
    "\n",
    "2. **Check for Missing Values:**\n",
    "   - `df_squirrels.isnull().sum()` calculates the total number of missing values in each column.\n",
    "   - Displays the number of missing values before any cleaning operations.\n",
    "\n",
    "3. **Identify Columns to Delete:**\n",
    "   - Columns with more than 50% missing values are identified and stored in `columns_to_delete`.\n",
    "\n",
    "4. **Delete Columns with Too Many Missing Values:**\n",
    "   - Deletes the identified columns from the dataset to minimize data loss.\n",
    "\n",
    "5. **Drop Rows with Remaining Missing Values:**\n",
    "   - Removes any rows that still contain missing values after deleting columns with excessive missing values.\n",
    "\n",
    "6. **Before and After Report:**\n",
    "   - Prints the number of rows and columns before and after the cleaning process to show the effect of the cleaning steps.\n",
    "\n",
    "7. **Optional Display of Cleaned DataFrame:**\n",
    "   - Displays the first five rows of the cleaned dataset to confirm the changes.ments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries of ChatBot Session: Question 8-9\n",
    "\n",
    "# Here's the final working version of your code, using the New York City Squirrel Census 2018 dataset, with all corrections applied to avoid the errors we discussed earlier:\n",
    "\n",
    "### Final Working Code\n",
    "\n",
    "```python\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the New York City Squirrel Census 2018 dataset from the provided URL\n",
    "url = \"https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv?accessType=DOWNLOAD\"\n",
    "df_squirrels = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(df_squirrels.head())\n",
    "\n",
    "# Example of using groupby to summarize the data\n",
    "# Grouping by 'Primary Fur Color' and describing 'Age' or any other numeric column\n",
    "# Note: Replace 'age' with the actual numeric column name if it is different\n",
    "grouped_data = df_squirrels.groupby('Primary Fur Color').describe()\n",
    "print(grouped_data)\n",
    "```\n",
    "\n",
    "### Explanation of the Final Code\n",
    "\n",
    "1. **Import the pandas library:**  \n",
    "   This is necessary to use pandas functions like `read_csv` and `groupby`.\n",
    "\n",
    "2. **Download and load the dataset from the URL:**  \n",
    "   The code loads the New York City Squirrel Census 2018 dataset directly from the provided URL using `pd.read_csv()`.\n",
    "\n",
    "3. **Display the first few rows of the dataset:**  \n",
    "   Using `print(df_squirrels.head())` allows you to visually verify that the data has been loaded correctly.\n",
    "\n",
    "4. **Group and summarize data:**  \n",
    "   The code demonstrates how to group the dataset by the 'Primary Fur Color' column and describe (summarize) the data using various statistical measures. Replace `\"Primary Fur Color\"` or `\"Age\"` with any relevant column name present in your dataset if needed.\n",
    "\n",
    "### Key Corrections Applied\n",
    "\n",
    "- **Included the pandas import statement** to ensure the `pd` alias is recognized.\n",
    "- **Corrected the URL** to avoid file not found errors.\n",
    "- **Ensured correct use of the DataFrame variable name** (`df_squirrels`).\n",
    "- **Proper syntax for function calls and grouping operations** (e.g., using `groupby` instead of `group_by`).\n",
    "- **Validated column names and ensured proper capitalization and use of strings**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
