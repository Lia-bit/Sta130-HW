{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5faee0",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- The key factor is whether the idea can be framed as a measurable and testable statement. For an idea to be statistically testable, it must be formulated in such a way that we can collect data to either support or refute it. This often involves making specific predictions about the population based on the sample data.\n",
    "- A good null hypothesis is a clear, precise, and falsifiable statement that reflects no effect or no relationship between variables. It must be testable using statistical methods and should be something that can be proven false (rejected) if there is evidence against it in the data.\n",
    "- The **null hypothesis (H₀)** represents the assumption that there is no effect or no difference, and it is what we test against. It assumes that any observed differences in data are due to random chance.\n",
    "- The **alternative hypothesis (H₁)** is the opposite of the null hypothesis and represents what the researcher expects or predicts. It suggests that there is a real effect or a significant difference between groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa5b89",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- The sentence \"It is important to note that the outcomes of tests refer to a population parameter, rather than a sample statistic! As such, the result that we get refers to the population\" alerts us to the difference between statistics of samples and parameters of populations in hypothesis testing. In other words, in any statistical testing we would like to infer something about a larger group (population) by observing or looking at a smaller group (sample). Even though we calculate averages from the sample, our conclusion is about the larger group, not about just the sample that we looked at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f14680",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- The reason we \"imagine a world where the null hypothesis is true\" when calculating a p-value is that the p-value measures how likely it is to observe our sample data (or something more extreme) if the null hypothesis were actually correct.\n",
    "- In other words, we start by assuming that there is no effect or no difference. Then, based on that assumption, we calculate the probability of getting our observed data purely by chance. If this probability (the p-value) is very low, it suggests that our data is unlikely to have occurred under the null hypothesis, leading us to question whether the null hypothesis is actually true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b2cc8",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- In hypothesis testing, when we compute a p-value, we presumptively take the null hypothesis to be true. In that case, the p-value will give us the probability of our data or something more extreme if the hypothesis actually is true. The smaller the p-value, the more improbable the data we observed are under the null hypothesis and thus the null hypothesis does not seem believable. This is so because the test statistic, which summarizes how far the sample data are from what we would expect if the null hypothesis were true, falls out in one of the extreme tails of the sampling distribution. A smaller p-value thus makes the null hypothesis increasingly \"ridiculous\" since it implies that the observed outcome is not likely to occur by random chance alone.\n",
    "\n",
    "### 3 Reasons\n",
    "\n",
    "1. **Test Statistic and Sampling Distribution**: When we perform a test of hypothesis, then we compute a test statistic. The expected distribution of this test statistic is known under the null hypothesis.\n",
    "\n",
    "2. Interpretation of the P-Value: This is the probability of getting a test statistic at least as extreme as what was observed under the condition that the null hypothesis is true. When this turns out to be very small, it strongly indicates that our test statistic is far away from what we would expect under the null hypothesis.\n",
    "\n",
    "3. **Smaller P-Value = Less Plausible Null Hypothesis**: If the p-value is small, it suggests that the observed data is highly incompatible with the world in which the null hypothesis is true. This makes the null hypothesis less credible or \"ridiculous,\" since it would be hard to argue that such extreme data happened just by random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92fd6c",
   "metadata": {},
   "source": [
    "# ChatBot Link (Q1-4)\n",
    "https://chatgpt.com/share/6707508c-e810-8012-8b7b-b941369fb82a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c76a27",
   "metadata": {},
   "source": [
    "# Chatbot Summary (Q1-4)\n",
    "- Here’s a summary of our exchanges for your homework submission:\n",
    "\n",
    "- We discussed key concepts in hypothesis testing as outlined in the \"first pre-lecture video\" and \"second pre-lecture video.\" First, we covered the importance of distinguishing between population parameters (like \\( \\mu \\)) and sample statistics (like \\( \\bar{x} \\)) in hypothesis testing. The null hypothesis (\\( H_0: \\mu = \\mu_0 \\)) represents no effect or difference, and the alternative hypothesis (\\( H_A \\)) suggests the opposite. The goal is to make inferences about the population using sample data. Next, we addressed why we \"imagine a world where the null hypothesis is true\" when calculating a p-value: the p-value represents how likely it is to observe the sample data if the null hypothesis is correct. Lastly, we discussed how smaller p-values make the null hypothesis seem less believable or \"ridiculous\" because they indicate that the observed data is highly unlikely to occur by random chance under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9578f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 5\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "n_couples = 124  # number of couples\n",
    "observed_tilt_right = 80  # observed couples tilting right\n",
    "n_simulations = 10000  # number of simulations\n",
    "\n",
    "# Simulate the null hypothesis (50% chance of tilting right for each couple)\n",
    "simulated_tilts = np.random.binomial(n=n_couples, p=0.5, size=n_simulations)\n",
    "\n",
    "# Calculate p-value: proportion of simulations with tilts >= observed\n",
    "p_value = np.mean(simulated_tilts >= observed_tilt_right)\n",
    "\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c5cde",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "### Interpretation:\n",
    "- Result: The p-value from the simulation is approximately 0.0006.\n",
    "\n",
    "Based on the evidence table:\n",
    "- 0.001≥p: Very strong evidence against the null hypothesis 𝐻0\n",
    "\n",
    "- This suggests that there is very strong evidence that couples tend to tilt their heads to the right when kissing, contrary to the null hypothesis of no tilt preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef74520",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- A smaller p-value cannot definitively prove that the null hypothesis is false. P-values only measure the strength of evidence against the null hypothesis. A low p-value suggests that the observed data is unlikely under the null hypothesis, but it does not provide absolute proof—there's always a possibility, however small, that the result occurred by chance.\n",
    "\n",
    "In the context of Fido's guilt or innocence:\n",
    "- A p-value cannot definitively prove Fido is innocent or guilty. It only indicates how surprising the observed evidence would be if Fido were innocent (the null hypothesis).\n",
    "- No matter how low or high the p-value, it cannot provide absolute proof. Even with a very low p-value, there's always some uncertainty—evidence points toward guilt or innocence but doesn't guarantee it.\n",
    "\n",
    "- Thus, p-values guide decision-making but do not offer definitive proof of guilt or innocence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723b9eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1737"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 7\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data for 'HealthScoreChange'\n",
    "# Creating a mock dataset based on what the question describes\n",
    "np.random.seed(0)\n",
    "patient_data = pd.DataFrame({\n",
    "    'HealthScoreChange': np.random.randn(10)  # 10 random health score changes\n",
    "})\n",
    "\n",
    "# Parameters\n",
    "np.random.seed(1)  # For reproducibility\n",
    "number_of_simulations = 10000\n",
    "n_size = len(patient_data)  # Size of the dataset\n",
    "\n",
    "# Observed statistic (proportion of improvements)\n",
    "observed_statistic = (patient_data['HealthScoreChange'] > 0).mean()\n",
    "\n",
    "# Generate null hypothesis data (simulated data under H0)\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    # Simulate random improvements under H0\n",
    "    random_improvement = np.random.choice([0, 1], size=n_size, replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "# Perform one-sided comparison\n",
    "SimStats_as_or_more_extreme_than_ObsStat = \\\n",
    "    IncreaseProportionSimulations_underH0random >= observed_statistic\n",
    "\n",
    "# Calculate one-sided p-value\n",
    "p_value_one_sided = np.mean(SimStats_as_or_more_extreme_than_ObsStat)\n",
    "\n",
    "p_value_one_sided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d60dc",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "### Steps to Adjust the Code:\n",
    "1. Modify the Comparison: Change the comparison from absolute deviations to checking only one side of the distribution.\n",
    "2. Update the p-value Calculation: The p-value is computed based on how often the simulated statistics are as extreme or more extreme in one direction.\n",
    "3. Interpret the Results: The one-sided test should give a smaller p-value if the observed data is consistent with the direction you're testing (e.g., the vaccine improves health scores). This is because you’re focusing on just one tail of the distribution.\n",
    "\n",
    "### Interpretation:\n",
    "- In the one-sided test, the p-value is smaller than the two-sided p-value because you are only considering deviations in one direction (i.e., greater than the observed statistic).\n",
    "- This change in the test narrows down the range of extreme values, which typically reduces the p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f349c",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "### Fisher's Tea Experiment: Statistical Analysis\n",
    "\n",
    "#### Problem Introduction:\n",
    "This analysis is inspired by Fisher's famous tea experiment, where the goal was to test whether Dr. Muriel Bristol could correctly identify the order in which milk and tea were poured. In this modified version, 80 STA130 students were asked to determine whether tea or milk was poured first, with 49 students correctly identifying the order. The purpose of this analysis is to statistically assess whether this result could have happened by random guessing or whether there is evidence that STA130 students are better than random guessing in identifying the pouring order.\n",
    "\n",
    "#### Relationship to the Original Experiment:\n",
    "In the original experiment, Fisher tested Dr. Bristol’s claim that she could distinguish between cups based on the pouring order. In contrast, this experiment involves a larger group of students, and the ability to distinguish the pouring order is more abstract. The original experiment involved personalized judgment, while the STA130 experiment tests for a general ability across a population.\n",
    "\n",
    "#### Hypotheses:\n",
    "\n",
    "1. **Null Hypothesis \\( H_0 \\)**:\n",
    "   - **Formal Statement**: The probability of a student correctly identifying the pouring order is 50%, meaning students are simply guessing.\n",
    "   - **Symbolic Form**: \\( H_0: p = 0.5 \\), where \\( p \\) is the proportion of correct identifications in the population.\n",
    "   - **Interpretation**: Under the null hypothesis, students are randomly guessing, and the proportion of correct identifications should be 50%.\n",
    "\n",
    "2. **Alternative Hypothesis \\( H_A \\)**:\n",
    "   - **Formal Statement**: The probability of correctly identifying the pouring order is greater than 50%, suggesting that students are better than random guessing.\n",
    "   - **Symbolic Form**: \\( H_A: p > 0.5 \\)\n",
    "   - **Interpretation**: This hypothesis posits that STA130 students have some ability to correctly identify the pouring order.\n",
    "\n",
    "#### Quantitative Analysis:\n",
    "We will perform a one-sided hypothesis test to evaluate whether 49 out of 80 students correctly identifying the pouring order provides evidence against the null hypothesis. A p-value will be calculated by simulating random guessing outcomes under the null hypothesis.\n",
    "\n",
    "#### Methodology:\n",
    "\n",
    "1. **Observed Test Statistic**:\n",
    "   - The observed statistic is the proportion of students who correctly identified the order: \\( \\hat{p} = \\frac{49}{80} = 0.6125 \\).\n",
    "\n",
    "2. **Simulation under \\( H_0 \\)**:\n",
    "   - We will simulate the scenario where students are randomly guessing (i.e., \\( p = 0.5 \\)) and calculate the proportion of correct identifications. We repeat this simulation many times (e.g., 10,000 times) to create a sampling distribution of the proportion under \\( H_0 \\).\n",
    "\n",
    "3. **P-value Calculation**:\n",
    "   - The p-value will be calculated as the proportion of simulated proportions that are greater than or equal to the observed proportion (0.6125).\n",
    "\n",
    "4. **Confidence Interval** (Optional):\n",
    "   - We can also calculate a confidence interval for the proportion of correct identifications to compare it with 0.5, although this is less common in hypothesis testing contexts.\n",
    "\n",
    "#### Findings:\n",
    "Based on the simulated p-value, we will interpret whether the result of 49 correct identifications provides strong evidence against the null hypothesis.\n",
    "\n",
    "#### Conclusion Regarding the Null Hypothesis:\n",
    "- If the p-value is small (e.g., less than 0.05), we can reject the null hypothesis and conclude that students are better than random guessing.\n",
    "- If the p-value is large (e.g., greater than 0.05), we fail to reject the null hypothesis, meaning there is insufficient evidence to conclude that students are better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd695bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 8\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_students = 80\n",
    "observed_correct = 49\n",
    "observed_proportion = observed_correct / n_students\n",
    "n_simulations = 10000\n",
    "\n",
    "# Simulate under the null hypothesis H0: p = 0.5\n",
    "simulated_proportions = np.random.binomial(n=n_students, p=0.5, size=n_simulations) / n_students\n",
    "\n",
    "# Calculate one-sided p-value (proportion of simulated statistics greater than or equal to observed)\n",
    "p_value = np.mean(simulated_proportions >= observed_proportion)\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982154cb",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "### Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b0c54",
   "metadata": {},
   "source": [
    "# Chatbot Link (Q5-9)\n",
    "https://chatgpt.com/share/670750e8-729c-8012-8ae3-3c39ce56c73b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad277a",
   "metadata": {},
   "source": [
    "# Chatbot Summary (Q5-9)\n",
    "### Summary of Interactions:\n",
    "\n",
    "1. **Initial Problem Setup**: \n",
    "   - You provided the context of Fisher's Tea Experiment, where 49 out of 80 STA130 students correctly identified the order of milk and tea in a cup.\n",
    "   - The goal was to assess whether this result could have occurred by random guessing or if there was evidence against the null hypothesis.\n",
    "\n",
    "2. **Null and Alternative Hypotheses**:\n",
    "   - **Null Hypothesis \\( H_0 \\)**: The probability of students correctly identifying the order of milk and tea is 50%, meaning students are randomly guessing.\n",
    "   - **Alternative Hypothesis \\( H_A \\)**: The probability of students correctly identifying the order is greater than 50%, indicating they are better than random guessing.\n",
    "\n",
    "3. **Simulation-Based Approach**:\n",
    "   - We used a simulation-based hypothesis test to calculate the p-value.\n",
    "   - Simulated the experiment under the null hypothesis (50% chance of guessing correctly) and repeated the process 10,000 times.\n",
    "   - The observed statistic was 49 correct identifications, giving an observed proportion of 0.6125.\n",
    "\n",
    "4. **Code Implementation**:\n",
    "   - We simulated the proportion of correct guesses under the null hypothesis and compared it to the observed statistic.\n",
    "   - The one-sided p-value was computed by finding the proportion of simulated proportions greater than or equal to 0.6125.\n",
    "\n",
    "5. **Results**:\n",
    "   - The calculated p-value was approximately **0.0294**.\n",
    "   - Since the p-value was less than the significance level of 0.05, we rejected the null hypothesis and concluded that the students were better than random guessing.\n",
    "\n",
    "6. **Conclusion**:\n",
    "   - There is statistical evidence to suggest that STA130 students have an ability to distinguish the order of milk and tea, rather than simply guessing.\n",
    "\n",
    "This summary can be used as part of your homework submission, documenting our interactions and the approach taken for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371836b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
